\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{luksan1999}
\citation{luksan1999}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Modified Newton Method}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Finite differences approximations}{4}{subsubsection.1.1.1}\protected@file@percent }
\newlabel{eq1}{{1}{5}{Finite differences approximations}{equation.1}{}}
\newlabel{eq3}{{2}{5}{Finite differences approximations}{equation.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Nelder--Mead Method}{6}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Rosenbrock Function in Dimension 2}{8}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem introduction}{8}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Surface plot of the Rosenbrock function over the domain $[-2, 2] \times [-1, 3]$. The function exhibits a narrow curved valley with a global minimum at $(1, 1)$, where $f(x) = 0$. This geometry makes it a standard benchmark for testing unconstrained optimization algorithms.}}{8}{figure.1}\protected@file@percent }
\newlabel{fig:rosennewton}{{1}{8}{Surface plot of the Rosenbrock function over the domain $[-2, 2] \times [-1, 3]$. The function exhibits a narrow curved valley with a global minimum at $(1, 1)$, where $f(x) = 0$. This geometry makes it a standard benchmark for testing unconstrained optimization algorithms}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Experimental results}{9}{subsection.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The table highlights the convergence results associated with the application of the Modified Newton method. The analysis takes into account the starting point, the value of the minimum and the value of the minimizer reached, and the number of iterations that were required to achieve these results.}}{9}{table.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Convergence behaviour of the Modified Newton method on the Rosenbrock function starting from $x_{A}^{(0)} = [1.2, 1.2]$ and $x_{B}^{(0)} = [-1.2, 1.0]$.}}{9}{figure.2}\protected@file@percent }
\newlabel{fig:rosennewton}{{2}{9}{Convergence behaviour of the Modified Newton method on the Rosenbrock function starting from $x_{A}^{(0)} = [1.2, 1.2]$ and $x_{B}^{(0)} = [-1.2, 1.0]$}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The table highlights the convergence results associated with the application of the Nelder--Mead method. The analysis takes into account the starting point, the value of the minimum and the value of the minimizer reached, and the number of iterations that were required to achieve these results.}}{10}{table.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Convergence behaviour of the Nelder--Mead method on the Rosenbrock function starting from $x^{(0)}_{A} = [1.2, 1.2]$ and $x^{(0)}_{B} = [-1.2, 1.0]$.}}{10}{figure.3}\protected@file@percent }
\newlabel{fig:rosennewton}{{3}{10}{Convergence behaviour of the Nelder--Mead method on the Rosenbrock function starting from $x^{(0)}_{A} = [1.2, 1.2]$ and $x^{(0)}_{B} = [-1.2, 1.0]$}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Extended Rosenbrock Function}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem introduction}{11}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 3D visualization of the Extended Rosenbrock function in dimension $n=2$. The global minimum lies at $(1,1)$, and the function exhibits a curved valley that becomes increasingly difficult to navigate in higher dimensions.}}{12}{figure.4}\protected@file@percent }
\newlabel{fig:extrosen3d}{{4}{12}{3D visualization of the Extended Rosenbrock function in dimension $n=2$. The global minimum lies at $(1,1)$, and the function exhibits a curved valley that becomes increasingly difficult to navigate in higher dimensions}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Modified Newton method}{12}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Modified Newton method with exact derivatives}{13}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The table highlights the convergence results associated with the application of the Modified Newton method with exact derivatives. The analysis takes into account the starting point (for the 10 random points an average behaviour is reported), the number of iterations that were required to achieve the result, the CPU time (s) and the rate of convergence $\rho $.}}{14}{table.3}\protected@file@percent }
\newlabel{table3}{{3}{14}{The table highlights the convergence results associated with the application of the Modified Newton method with exact derivatives. The analysis takes into account the starting point (for the 10 random points an average behaviour is reported), the number of iterations that were required to achieve the result, the CPU time (s) and the rate of convergence $\rho $}{table.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{14}{section*.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Convergence of the Modified Newton method with exact derivatives on the Extended Rosenbrock function for $n=1000$. Each curve corresponds to a different initial point. The method converges quadratically with stable behaviour across all tests.}}{15}{figure.5}\protected@file@percent }
\newlabel{fig:extnewton_1k}{{5}{15}{Convergence of the Modified Newton method with exact derivatives on the Extended Rosenbrock function for $n=1000$. Each curve corresponds to a different initial point. The method converges quadratically with stable behaviour across all tests}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=10\,000$. The method exhibits consistent quadratic convergence also in higher dimension.}}{15}{figure.6}\protected@file@percent }
\newlabel{fig:extnewton_10k}{{6}{15}{Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=10\,000$. The method exhibits consistent quadratic convergence also in higher dimension}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=100\,000$. Despite the high dimensionality, the convergence remains stable with similar iteration counts.}}{16}{figure.7}\protected@file@percent }
\newlabel{fig:extnewton_100k}{{7}{16}{Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=100\,000$. Despite the high dimensionality, the convergence remains stable with similar iteration counts}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Execution time (in seconds) of the Modified Newton method with exact derivatives for $n=10^3$, $10^4$ and $10^5$. The runtime grows approximately linearly with the problem size, confirming the efficiency of sparse matrix operations.}}{16}{figure.8}\protected@file@percent }
\newlabel{fig:extnewton_times}{{8}{16}{Execution time (in seconds) of the Modified Newton method with exact derivatives for $n=10^3$, $10^4$ and $10^5$. The runtime grows approximately linearly with the problem size, confirming the efficiency of sparse matrix operations}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Modified Newton method with approximated derivatives}{16}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient approximation.}{17}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hessian approximation.}{17}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{18}{section*.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Finite difference results using different typology of increments ($n = 10^{3}$).}}{19}{table.4}\protected@file@percent }
\newlabel{tab:fd_ext_1000}{{4}{19}{Finite difference results using different typology of increments ($n = 10^{3}$)}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{3}$ with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{20}{figure.9}\protected@file@percent }
\newlabel{fig:fd_1k_h2}{{9}{20}{Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{3}$ with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{3}$ with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{20}{figure.10}\protected@file@percent }
\newlabel{fig:fd_1k_h12}{{10}{20}{Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{3}$ with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Finite difference results for using different typology of increments ($n = 10^{4}$).}}{21}{table.5}\protected@file@percent }
\newlabel{tab:fd_er_10000}{{5}{21}{Finite difference results for using different typology of increments ($n = 10^{4}$)}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{4}$ with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{22}{figure.11}\protected@file@percent }
\newlabel{fig:fd_10k_h2}{{11}{22}{Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{4}$ with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{4}$ with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{22}{figure.12}\protected@file@percent }
\newlabel{fig:fd_10k_h12}{{12}{22}{Convergence of Modified Newton method on Extended Rosenbrock function in dimension $n = 10^{4}$ with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.12}{}}
\newlabel{tab:fd_rosenbrock_100000}{{3.2.2}{23}{Experimental results}{figure.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Finite difference results using different increments ($n = 10^{5}$).}}{23}{table.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n = 10^{5}$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{24}{figure.13}\protected@file@percent }
\newlabel{fig:fd_100k_h2}{{13}{24}{Convergence of Modified Newton method on Extended Rosenbrock function ($n = 10^{5}$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n = 10^{5}$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{24}{figure.14}\protected@file@percent }
\newlabel{fig:fd_100k_h12}{{14}{24}{Convergence of Modified Newton method on Extended Rosenbrock function ($n = 10^{5}$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Nelder–Mead method}{25}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{25}{section*.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Results of Nelder–Mead on Extended Rosenbrock function.}}{26}{table.7}\protected@file@percent }
\newlabel{tab:nelder_rosenbrock}{{7}{26}{Results of Nelder–Mead on Extended Rosenbrock function}{table.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=10$) from reference and 10 random initial points. The objective decreases but stagnates above the global minimum.}}{26}{figure.15}\protected@file@percent }
\newlabel{fig:nelder_rosen_10}{{15}{26}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=10$) from reference and 10 random initial points. The objective decreases but stagnates above the global minimum}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=26$). Progress slows down and most trajectories fail to improve after early iterations.}}{27}{figure.16}\protected@file@percent }
\newlabel{fig:nelder_rosen_26}{{16}{27}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=26$). Progress slows down and most trajectories fail to improve after early iterations}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=50$). None of the trials reach satisfactory objective values, confirming the method’s limits in high dimensions.}}{27}{figure.17}\protected@file@percent }
\newlabel{fig:nelder_rosen_50}{{17}{27}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=50$). None of the trials reach satisfactory objective values, confirming the method’s limits in high dimensions}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Execution time of Nelder–Mead on Extended Rosenbrock for increasing dimensions $n=10$, $26$, and $50$. The cost grows sharply due to the increased simplex size.}}{28}{figure.18}\protected@file@percent }
\newlabel{fig:nelder_rosen_times}{{18}{28}{Execution time of Nelder–Mead on Extended Rosenbrock for increasing dimensions $n=10$, $26$, and $50$. The cost grows sharply due to the increased simplex size}{figure.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Generalized Broyden Tridiagonal Function}{29}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Problem introduction}{29}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces 3D visualization of the Generalized Broyden Tridiagonal function for $n=2$.}}{29}{figure.19}\protected@file@percent }
\newlabel{fig:broyden3D}{{19}{29}{3D visualization of the Generalized Broyden Tridiagonal function for $n=2$}{figure.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Modified Newton method}{30}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Modified Newton method with exact derivatives}{31}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{tab:gb_exact_al}{{4.2.1}{31}{Modified Newton method with exact derivatives}{subsubsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Results of Modified Newton method on Generalized Broyden function using exact derivatives.}}{31}{table.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{31}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=1000$ using exact gradient and Hessian. The method converges in few iterations with a consistent superlinear rate.}}{32}{figure.20}\protected@file@percent }
\newlabel{fig:gb_1k_exact}{{20}{32}{Convergence of the Modified Newton method on Generalized Broyden function with $n=1000$ using exact gradient and Hessian. The method converges in few iterations with a consistent superlinear rate}{figure.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=10000$. The convergence behavior remains stable across all random initializations.}}{33}{figure.21}\protected@file@percent }
\newlabel{fig:gb_10k_exact}{{21}{33}{Convergence of the Modified Newton method on Generalized Broyden function with $n=10000$. The convergence behavior remains stable across all random initializations}{figure.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=100000$. Even in high dimensions, the algorithm remains robust and fast.}}{33}{figure.22}\protected@file@percent }
\newlabel{fig:gb_100k_exact}{{22}{33}{Convergence of the Modified Newton method on Generalized Broyden function with $n=100000$. Even in high dimensions, the algorithm remains robust and fast}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Execution time of the Modified Newton method with exact derivatives on Generalized Broyden function for increasing dimensions. The computation scales efficiently due to sparse Hessian structure.}}{34}{figure.23}\protected@file@percent }
\newlabel{fig:gb_time_exact}{{23}{34}{Execution time of the Modified Newton method with exact derivatives on Generalized Broyden function for increasing dimensions. The computation scales efficiently due to sparse Hessian structure}{figure.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Modified Newton method with approximated derivatives}{34}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient approximation.}{34}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hessian approximation.}{35}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{35}{section*.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Finite differences results for $n=1000$ using different increments $h$.}}{36}{table.9}\protected@file@percent }
\newlabel{tab:gb_fd_1000_all}{{9}{36}{Finite differences results for $n=1000$ using different increments $h$}{table.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{37}{figure.24}\protected@file@percent }
\newlabel{fig:fd_broyden_1k_h2}{{24}{37}{Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{37}{figure.25}\protected@file@percent }
\newlabel{fig:fd_broyden_1k_h12}{{25}{37}{Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.25}{}}
\newlabel{tab:gb_fd_10000}{{4.2.2}{38}{Experimental results}{figure.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Finite difference results for $n=10\,000$ using different increments $h$.}}{38}{table.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{39}{figure.26}\protected@file@percent }
\newlabel{fig:fd_broyden_10k_h2}{{26}{39}{Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{39}{figure.27}\protected@file@percent }
\newlabel{fig:fd_broyden_10k_h12}{{27}{39}{Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.27}{}}
\newlabel{tab:gb_fd_100000}{{4.2.2}{40}{Experimental results}{figure.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Finite difference results for $n=100\,000$ using different increments $h$.}}{40}{table.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{41}{figure.28}\protected@file@percent }
\newlabel{fig:fd_broyden_100k_h2}{{28}{41}{Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{41}{figure.29}\protected@file@percent }
\newlabel{fig:fd_broyden_100k_h12}{{29}{41}{Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Nelder–Mead method}{42}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Results of Nelder–Mead on Generalized Broyden tridiagonal function.}}{42}{table.12}\protected@file@percent }
\newlabel{tab:nelder_broyden}{{12}{42}{Results of Nelder–Mead on Generalized Broyden tridiagonal function}{table.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{43}{section*.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=10$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{43}{figure.30}\protected@file@percent }
\newlabel{fig:gb_nelder_10}{{30}{43}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=10$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=26$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{44}{figure.31}\protected@file@percent }
\newlabel{fig:gb_nelder_26}{{31}{44}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=26$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=50$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{45}{figure.32}\protected@file@percent }
\newlabel{fig:gb_nelder_50}{{32}{45}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=50$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Computational time (in seconds) for Nelder-Mead method applied to the Generalized Broyden function for increasing dimensions.}}{45}{figure.33}\protected@file@percent }
\newlabel{fig:gb_nelder_time}{{33}{45}{Computational time (in seconds) for Nelder-Mead method applied to the Generalized Broyden function for increasing dimensions}{figure.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Banded Trigonometric Function}{46}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Problem introduction}{46}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces 3D visualization of the Banded Trigonometric function for $n=2$.}}{46}{figure.34}\protected@file@percent }
\newlabel{fig:banded3D}{{34}{46}{3D visualization of the Banded Trigonometric function for $n=2$}{figure.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Modified Newton method}{47}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Modified Newton method with exact derivatives}{48}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental Results.}{49}{section*.12}\protected@file@percent }
\newlabel{tab:banded_exact}{{5.2.1}{49}{Experimental Results}{section*.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Results of Modified Newton method on Banded Trigonometric function using exact derivatives.}}{49}{table.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using exact derivatives.}}{50}{figure.35}\protected@file@percent }
\newlabel{fig:bt_1k_exact}{{35}{50}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using exact derivatives}{figure.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using exact derivatives.}}{50}{figure.36}\protected@file@percent }
\newlabel{fig:bt_10k_exact}{{36}{50}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using exact derivatives}{figure.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using exact derivatives.}}{51}{figure.37}\protected@file@percent }
\newlabel{fig:bt_100k_exact}{{37}{51}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using exact derivatives}{figure.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Computational time required by the Modified Newton method on the Banded Trigonometric function with exact derivatives for each problem size.}}{51}{figure.38}\protected@file@percent }
\newlabel{fig:bt_time_exact}{{38}{51}{Computational time required by the Modified Newton method on the Banded Trigonometric function with exact derivatives for each problem size}{figure.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Modified Newton method with approximated derivatives}{52}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient approximation.}{52}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hessian approximation.}{52}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental Results.}{53}{section*.15}\protected@file@percent }
\newlabel{tab:banded_fd_1000}{{5.2.2}{54}{Experimental Results}{section*.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Finite difference results for $n=1\,000$ using different increments $h$ and strategies.}}{54}{table.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{55}{figure.39}\protected@file@percent }
\newlabel{fig:bt_fd_1k_h2}{{39}{55}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{55}{figure.40}\protected@file@percent }
\newlabel{fig:bt_fd_1k_h12}{{40}{55}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.40}{}}
\newlabel{tab:bt_fd_10000}{{5.2.2}{56}{Experimental Results}{figure.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Finite difference results for $n=10\,000$ using different increments $h$ and strategies.}}{56}{table.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{57}{figure.41}\protected@file@percent }
\newlabel{fig:bt_fd_10k_h2}{{41}{57}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{57}{figure.42}\protected@file@percent }
\newlabel{fig:bt_fd_10k_h12}{{42}{57}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.42}{}}
\newlabel{tab:banded_fd_100000}{{5.2.2}{58}{Experimental Results}{figure.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Finite difference results for $n=100\,000$ using different increments $h$ and strategies.}}{58}{table.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{59}{figure.43}\protected@file@percent }
\newlabel{fig:bt_fd_100k_h2}{{43}{59}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{59}{figure.44}\protected@file@percent }
\newlabel{fig:bt_fd_100k_h12}{{44}{59}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Nelder–Mead method}{60}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{60}{section*.16}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Results of Nelder–Mead on Banded Trigonometric function.}}{61}{table.17}\protected@file@percent }
\newlabel{tab:nelder_bandedtrig}{{17}{61}{Results of Nelder–Mead on Banded Trigonometric function}{table.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 10$.}}{62}{figure.45}\protected@file@percent }
\newlabel{fig:bt_nelder_10}{{45}{62}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 10$}{figure.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 26$.}}{62}{figure.46}\protected@file@percent }
\newlabel{fig:bt_nelder_26}{{46}{62}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 26$}{figure.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 50$.}}{63}{figure.47}\protected@file@percent }
\newlabel{fig:bt_nelder_50}{{47}{63}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 50$}{figure.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Computation time of Nelder-Mead on the Banded Trigonometric function for $n \in \{10, 26, 50\}$.}}{63}{figure.48}\protected@file@percent }
\newlabel{fig:bt_nelder_time}{{48}{63}{Computation time of Nelder-Mead on the Banded Trigonometric function for $n \in \{10, 26, 50\}$}{figure.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{64}{section.6}\protected@file@percent }
\gdef \@abspage@last{66}
